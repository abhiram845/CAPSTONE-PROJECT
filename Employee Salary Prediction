# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import LabelEncoder

# Load the dataset
# Use your dataset or this dummy CSV link if needed
# For real project, replace this with actual path: pd.read_csv("employee_data.csv")
data = pd.DataFrame({
    'Experience': [1, 3, 5, 7, 9, 11, 13],
    'Education': ['Bachelors', 'Bachelors', 'Masters', 'Masters', 'PhD', 'PhD', 'PhD'],
    'Role': ['Analyst', 'Analyst', 'Manager', 'Manager', 'Director', 'Director', 'VP'],
    'Salary': [35000, 45000, 65000, 75000, 90000, 110000, 150000]
})

# Display the first few rows
print("Dataset Preview:")
print(data.head())

# Encode categorical features
le_education = LabelEncoder()
le_role = LabelEncoder()

data['Education'] = le_education.fit_transform(data['Education'])
data['Role'] = le_role.fit_transform(data['Role'])

# Define features and label
X = data[['Experience', 'Education', 'Role']]
y = data['Salary']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluation
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"\nModel Evaluation:\nRÂ² Score: {r2:.2f}\nRMSE: {rmse:.2f}")

# Visualize Predictions vs Actual
plt.figure(figsize=(6,4))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([y.min(), y.max()], [y.min(), y.max()], color='red', linestyle='--')
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.title("Actual vs Predicted Salary")
plt.grid(True)
plt.tight_layout()
plt.show()
